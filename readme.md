```markdown
# Natural-Language to Pandas with LLMs  
_Auto-generating, sandbox-executing & verifying code on the UCI â€œIndividual Household Power Consumptionâ€ dataset_

---

## Project Overview
This repository demonstrates an end-to-end workflow in which a Large Language Model (LLM) converts plain-English analytical questions into executable **Pandas** code.  
Key points:

* **Dataset**â€ƒUCI Household Power Consumption (Dec-2006 â†’ Nov-2010, 2 M rows).  
* **Model**â€ƒ`llama3-8b-instruct` served through the **Groq** API.  
* **Safety**â€ƒGenerated code runs in an isolated namespace with `df.copy(deep=True)` so the master DataFrame is never mutated.  
* **Verification**â€ƒEach LLM answer is compared against a ground-truth snippet; results are displayed in a score table.

---

## Repository Layout
```

|â”€â”€ household_power_consumption.txt   # raw UCI text file 127 MB
â”œâ”€â”€ llm_queries.ipynb                     # Jupyter notebook (main pipeline)
â”œâ”€â”€ helper.py                             # Groq wrapper + secure exec helpers
â”œâ”€â”€ environment.yml                       # Conda environment (Python 3.11)
â””â”€â”€ README.md                             # /power-llm.git
cd power-llm

# create and activate the exact environment
conda env create -f environment.yml
conda activate energy-llm
```

### 2 Â· Provide your Groq API key
```
export GROQ_API_KEY="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

### 3 Â· Run the notebook
```
jupyter lab          # or: jupyter notebook
# open `llm_queries.ipynb` and Run â–¶ all cells
```
A results table will appear; the `is_match` column should read **True** for every row.

---

## ğŸ“ Notebook Walk-Through
| Step | Purpose |
|-----:|---------|
| 1 | Load the raw text file â†’ parse dates â†’ create a `DateTimeIndex`. |
| 2 | Define seven benchmark questions + reference Pandas solutions. |
| 3 | Build a strict **system prompt** demanding pure code in triple back-ticks. |
| 4 | Call Groq â†’ Llama-3 to get code for each question. |
| 5 | **Sandbox exec:** run code in a namespace containing only `df.copy(deep=True)` and std-lib. |
| 6 | Compare model output with ground truth â†’ tabulate accuracy. |

---
 

---
 

## ğŸ“Š Extending the Benchmark
Add more Q&A pairs in the `SOLUTIONS` dict inside the notebook.  
The evaluation cells automatically pick them up and add rows to the score table.

---

## âš™ï¸ Dependencies
* Python 3.11
* pandas â‰¥ 2.2
* matplotlib â‰¥ 3.9
* groq â‰¥ 0.7
* jupyterlab / notebook  

Full, pinned versions live in `environment.yml`.

 